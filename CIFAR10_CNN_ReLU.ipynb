{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10_CNN_ReLU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HxJYuaOPAmPv"},"source":["import multiprocessing \n","\n","import six\n","import numpy as np\n","import tensorflow.compat.v2 as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","\n","!pip install git+https://github.com/google/qkeras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOmxo96CBcCy"},"source":["from tensorflow.keras.datasets import cifar10\n","\n","def get_data():\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","    #x_train, x_test = tf.image.rgb_to_grayscale(x_train).numpy(), tf.image.rgb_to_grayscale(x_test).numpy()\n","    #x_train = np.average(x_train, axis=3, weights=[0.2125, 0.7154, 0.0721]) \n","    #x_test = np.average(x_test, axis=3, weights=[0.2125, 0.7154, 0.0721])\n","    #cv2_imshow(x_train[4])\n","    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n","    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n","\n","    print (np.max(x_train), np.max(x_test))\n","    x_train /= 256.0\n","    x_test /= 256.0\n","\n","    x_mean = np.mean(x_train, axis=0)\n","\n","    x_train -= x_mean\n","    x_test -= x_mean\n","\n","    nb_classes = np.max(y_train)+1\n","    y_train = to_categorical(y_train, nb_classes)\n","    y_test = to_categorical(y_test, nb_classes)\n","\n","    #quantizer = quantized_bits(17, 1)\n","    #x_train = quantizer(x_train)\n","    #x_test = quantizer(x_test)\n","\n","    return (x_train, y_train), (x_test, y_test)\n","\n","(x_train, y_train), (x_test, y_test) = get_data()\n","print (x_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RRNFy7iHGsMS"},"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cEEV7FxHBc4Z"},"source":["from qkeras import *\n","import qkeras\n","from qkeras.utils import *\n","\n","def CreateQModel(shape, nb_classes, intBits):\n","    x = x_in = Input(shape)\n","\n","    x = QConv2D(32, (3, 3),\n","                kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","                bias_quantizer=\"quantized_bits(17, {} , alpha = 1)\".format(intBits),\n","                name='c1')(x)\n","    x = QActivation('quantized_relu(17, {})'.format(intBits))(x)\n","    x = MaxPooling2D((2,2))(x)\n","\n","    x = QConv2D(64, (3, 3),\n","                kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","                bias_quantizer=\"quantized_bits(17, {} , alpha = 1)\".format(intBits),\n","                name=\"c2\")(x)\n","    x = QActivation('quantized_relu(17, {})'.format(intBits))(x)\n","    x = MaxPooling2D((2,2))(x)\n","\n","    x = QConv2D(64, (3, 3),\n","                kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","                bias_quantizer=\"quantized_bits(17, {} , alpha = 1)\".format(intBits),\n","                name='c3')(x)\n","    x = QActivation('quantized_relu(17, {})'.format(intBits))(x)\n","\n","    x = Flatten(name=\"flatten\")(x)\n","\n","    x = QDense(64,\n","        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","        bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","        name=\"dense3\")(x)\n","    x = QActivation('quantized_relu(17, {})'.format(intBits))(x)\n","\n","    x = QDense(nb_classes,\n","        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","        bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n","        name=\"dense4\")(x)\n","    x = Activation(\"softmax\", name=\"softmax\")(x)\n","\n","\n","    model = Model(inputs=x_in, outputs=x)\n","    \n","    return model\n","\n","from tensorflow.keras.optimizers import Adam\n","model = CreateQModel(x_train.shape[1:], y_train.shape[-1], 1)\n","model.compile(\n","    loss=\"categorical_crossentropy\",\n","    #loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=Adam(0.1),\n","    #optimizer='sgd',\n","    metrics=[\"accuracy\"])\n","history = model.fit(x_train, y_train, epochs=10, batch_size=256, validation_data=(x_test[:5000], y_test[:5000]), verbose=True) # callbacks=[callback])\n","model_save_quantized_weights(model)\n","print (\"Done\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DdF6i-ZOPn4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ELP-dOZIWd1s"},"source":["# Tensorflow Colab file with some modifications"]},{"cell_type":"code","metadata":{"id":"6du4sCo7Wifx"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","from qkeras import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cat1JGJYWnY8"},"source":["(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-C9Zc2lWqx6"},"source":["intBits = 1\n","precision = 17\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","#model.add(QConv2D(32, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        activation='quantized_relu({}, {})'.format(precision, intBits),\n","#        name='c1'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","#model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        activation='quantized_relu({}, {})'.format(precision, intBits),\n","#        name='c2'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","#model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        activation='quantized_relu({}, {})'.format(precision, intBits),\n","#        name='c3'))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","#model.add(QDense(64, kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","#        name='d1'))\n","#model.add(QActivation('quantized_relu({}, {})'.format(precision, intBits)))\n","model.add(layers.Dense(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJfLC9yrWu3Z"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit(train_images, train_labels, epochs=10, \n","                    validation_data=(test_images[:5000], test_labels[:5000]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lw5LYwqdbR54"},"source":["import qkeras\n","from qkeras import *\n","from qkeras.utils import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86ytLEYSbZ0e"},"source":["model_save_quantized_weights(model)\n","print (\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x89GmBLzbfXZ"},"source":["model.evaluate(test_images[5000:], test_labels[5000:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgG4J9qoeE3n"},"source":["### Evaluation in a loop\n","intBits = 1\n","histories = []\n","mymodels = []\n","for precision in [8, 12, 16, 24, 32]:\n","  model = models.Sequential()\n","  #model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","  model.add(QConv2D(32, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        activation='quantized_relu({}, {})'.format(precision, intBits),\n","        name='c1'))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  #model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        activation='quantized_relu({}, {})'.format(precision, intBits),\n","        name='c2'))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  #model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        activation='quantized_relu({}, {})'.format(precision, intBits),\n","        name='c3'))\n","\n","  model.add(layers.Flatten())\n","  #model.add(layers.Dense(64, activation='relu'))\n","  model.add(QDense(64, kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","        name='d1'))\n","  model.add(QActivation('quantized_relu({}, {})'.format(precision, intBits)))\n","  model.add(layers.Dense(10))\n","\n","  model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","  history = model.fit(train_images, train_labels, epochs= 5 + int(3*((precision/8) - 1)), \n","                    validation_data=(test_images[:5000], test_labels[:5000]), verbose=False)\n","  \n","  model_save_quantized_weights(model)\n","  print (\"Done\")\n","\n","  model.evaluate(test_images[5000:], test_labels[5000:])\n","\n","  mymodels.append(model)\n","  histories.append(history)"],"execution_count":null,"outputs":[]}]}