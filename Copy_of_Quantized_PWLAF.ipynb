{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Quantized_PWLAF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xU3goZ11jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb146111-a89e-47ff-8e6e-ab3fba92dbba"
      },
      "source": [
        "import six\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "!pip install git+https://github.com/google/qkeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google/qkeras\n",
            "  Cloning https://github.com/google/qkeras to /tmp/pip-req-build-al85ld7b\n",
            "  Running command git clone -q https://github.com/google/qkeras /tmp/pip-req-build-al85ld7b\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.4.1)\n",
            "Collecting pyparser\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/7c/77a059dcf29b39e6c4315ce9e9c7d4959be6f13af8ee42e6d5376b599015/pyparser-1.0.tar.gz\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (53.0.0)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (2.5)\n",
            "Collecting keras-tuner>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/4c/6111b9a325f29527d7f262e2ee8c730d354b47a728d955e186dacad57a0d/scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.4MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.48.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/13/f3f815bb73804a8af9cfbb6f084821c037109108885f46131045e8cf044e/tqdm-4.57.0-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hCollecting parse==1.6.5\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/eb/44c70a5704fdf55d26a33070a9a13a03f0d66a5f6b72cadf75620d9dc4c0/parse-1.6.5.tar.gz\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (0.1.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->QKeras==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (2.23.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner>=1.0.1->QKeras==0.8.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (1.24.3)\n",
            "Building wheels for collected packages: QKeras, pyparser, keras-tuner, parse, terminaltables\n",
            "  Building wheel for QKeras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for QKeras: filename=QKeras-0.8.0-cp36-none-any.whl size=148269 sha256=c4fbdc331fd4c2fd9f4c396d738ad0bb0631f056c5805f653d8c841867dbb30d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q4aromrg/wheels/b4/74/1d/9456d62789716894a5edd7e342b4beaef69241ac584706c68d\n",
            "  Building wheel for pyparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyparser: filename=pyparser-1.0-cp36-none-any.whl size=4944 sha256=2cfe95f651e8d7a550e542d38574ae0d29dc8049b1ea731539650cca829c12c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/1c/4f/9f66cd69719aa41c2684efae758d95db7803e9fe1f65146db1\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=01ea7dfb6dec3c202f7f87a223d1225dca8c136db380acebeda75c8abee3841a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.6.5-cp36-none-any.whl size=18178 sha256=7463d5a6f75c2c3f40129bb1903bfb03a69f10fa819b57e9b8f85805042c6cf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/cd/20/b1fc8e3046811c0d10f03d1027c26077c9ca396cf8d579f4e3\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=d91057dc20cc30883319baeada5f210af51704a63b3332cfdfcc5501cf1ed1bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built QKeras pyparser keras-tuner parse terminaltables\n",
            "Installing collected packages: parse, pyparser, tensorflow-model-optimization, terminaltables, colorama, tqdm, threadpoolctl, scikit-learn, keras-tuner, QKeras\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed QKeras-0.8.0 colorama-0.4.4 keras-tuner-1.0.2 parse-1.6.5 pyparser-1.0 scikit-learn-0.24.1 tensorflow-model-optimization-0.5.0 terminaltables-3.1.0 threadpoolctl-2.1.0 tqdm-4.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeGejv5F2FFV"
      },
      "source": [
        "def get_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
        "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
        "\n",
        "    x_train /= 256.0\n",
        "    x_test /= 256.0\n",
        "\n",
        "    x_mean = np.mean(x_train, axis=0)\n",
        "\n",
        "    x_train -= x_mean\n",
        "    x_test -= x_mean\n",
        "\n",
        "    nb_classes = np.max(y_train)+1\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    quantizer = quantized_bits(9, 1)\n",
        "    x_train = quantizer(x_train).numpy()\n",
        "    x_test = quantizer(x_test).numpy()\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CliMUn61NM51"
      },
      "source": [
        "### Here I'll try to use the method outlined in this link\n",
        "# https://stackoverflow.com/questions/54204393/piecewise-activation-function-in-tensorflow-and-broadcasting-math-operation\n",
        "\n",
        "def swish(x):\n",
        "  global intervals, coeffArray\n",
        "  #return x\n",
        "  coeff = np.array(coeffArray)\n",
        "  conditionArray = sum([tf.multiply(tf.cast(tf.math.logical_and(tf.math.less(x, 0.03125*(n+1)), tf.math.greater_equal(x, 0.03125*n)), tf.float32), coeff[n][0]*x + coeff[n][1]*K.ones_like(x)) for n in range(256)])\n",
        "\n",
        "  #return quantized_bits(17, 1)(conditionArray)\n",
        "  return conditionArray\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g372k7ea2UmL"
      },
      "source": [
        "from qkeras import *\n",
        "import qkeras\n",
        "def CreateModel(shape, nb_classes, intBits):\n",
        "    x = x_in = Input(shape)\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "\n",
        "    #x = QDense(256,\n",
        "    #    kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    bias_quantizer=\"quantized_bits(17, {} , alpha = 1)\".format(intBits),\n",
        "    #    name=\"dense\")(x)\n",
        "    x = Dense(256)(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    #x = QDense(128,\n",
        "    #    kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    name=\"dense2\")(x)\n",
        "    x = Dense(128)(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    #x = QDense(128,\n",
        "    #    kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    name=\"dense3\")(x)\n",
        "    x = Dense(128)(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    #x = QDense(nb_classes,\n",
        "    #    kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "    #    name=\"dense4\")(x)\n",
        "    x = Dense(nb_classes)(x)\n",
        "    \n",
        "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYwiSVce2O3N"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=2, restore_best_weights=True)\n",
        "\n",
        "model = CreateModel(x_train.shape[1:], y_train.shape[-1], 1)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(0.0005),\n",
        "    #optimizer='sgd',\n",
        "    metrics=[\"accuracy\"],)\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=128, validation_data=(x_test[:5000], y_test[:5000]), verbose=False, callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuNIQuD5n2-r"
      },
      "source": [
        "from qkeras.utils import *\n",
        "model_save_quantized_weights(model)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNkFu80c2kPa"
      },
      "source": [
        "model.evaluate(x_test[5000:], y_test[5000:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYwcmp5qTgI"
      },
      "source": [
        "# PWLAF\n",
        "\n",
        "e --> Error\n",
        "r --> Input Range\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D6a_oPdtl3W"
      },
      "source": [
        "from scipy.optimize import fsolve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6s8DQvw-Lih"
      },
      "source": [
        "#Given\n",
        "e = 0.04\n",
        "r = 8\n",
        "\n",
        "#Number of input bits\n",
        "Ninp = np.ceil(np.log(r)/np.log(2)) + np.ceil(-1*np.log(e)/np.log(2))\n",
        "\n",
        "#Number of Output/Fractional bits\n",
        "Nout = np.ceil(-1*np.log(e)/np.log(2))\n",
        "\n",
        "#Boundaries\n",
        "def f(x):\n",
        "  global e\n",
        "  return (x**3)/3 - (2*(x**5)/15 + e)\n",
        "\n",
        "xpa = fsolve(f, [1])[0]\n",
        "xpaq = r*np.ceil(xpa* (2**(Ninp))/r)/(2**Ninp)\n",
        "\n",
        "temp = 1-(e + 2**(-1*Nout))\n",
        "xs = np.arctanh(temp)\n",
        "xsq = r*np.ceil(xs* (2**(Ninp))/r)/(2**Ninp)\n",
        "\n",
        "#Permissible approximation error\n",
        "ea = e - 2**(-1*(Nout+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiqldig7amJ-"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-1*x))\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLAMQQHZuKQ6",
        "outputId": "e3d0b0e1-6559-4883-e114-0f81ae0e47e1"
      },
      "source": [
        "import scipy.integrate as integrate\n",
        "import scipy.special as special\n",
        "result = integrate.quad(lambda x: tanh(x), 0, 4.5)\n",
        "result[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.806976221629778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQgHXx70HkV8"
      },
      "source": [
        "We divide the given range into 256 equal segments. In each segment, we wish to make the area equal to that under the actual function.\n",
        "\n",
        "In each sub-interval we choose from a set of further 100 points, to determine thw optimal values of the constants c1 and c2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qWplFqIH9do"
      },
      "source": [
        "given_range = [-4, 4]\n",
        "\n",
        "intervals = np.linspace(given_range[0], given_range[1], 257)\n",
        "from qkeras import *\n",
        "quantizer = quantized_bits(9, 3)\n",
        "intervals = sorted(list(set(quantizer(intervals).numpy())))\n",
        "#intervals.append(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdlYmE4kXN1P",
        "outputId": "da677047-6e26-433e-e093-06981cd01b2f"
      },
      "source": [
        "len(intervals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eYbzfH3W05u",
        "outputId": "b5c1e8fb-8ef1-4313-fe85-cfec21a4df2c"
      },
      "source": [
        "intervals[::-1][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.0,\n",
              " 3.968628,\n",
              " 3.9372559,\n",
              " 3.9058838,\n",
              " 3.8745117,\n",
              " 3.8431396,\n",
              " 3.8117676,\n",
              " 3.7803955,\n",
              " 3.7490234,\n",
              " 3.7176514]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWjyr3H8KrsC"
      },
      "source": [
        "from scipy import linalg\n",
        "import math\n",
        "def findOptimalPoint(a, b, func):\n",
        "  ans = []\n",
        "  error = []\n",
        "  #print (error)\n",
        "  compare1 = np.array([sigmoid(x) for x in np.linspace(a,b, 10)])\n",
        "  for c in np.linspace(a, b, 10):\n",
        "    \n",
        "    if c == a or c==b:\n",
        "      pass\n",
        "    TrueArea1 = integrate.quad(lambda x: func(x), a, c)[0]\n",
        "    TrueArea2 = integrate.quad(lambda x: func(x), c, b)[0]\n",
        "    \n",
        "    #print (TrueArea1, TrueArea2)\n",
        "    \n",
        "      #solution = linalg.solve(np.array([[0.5*c**2 - 0.5*a**2, c-a], [0.5*b**2 - 0.5*c**2, b-c]]), np.array([TrueArea1, TrueArea2]))\n",
        "      #c1, c2 = solution[0], solution[1]\n",
        "\n",
        "    den1 = 0.5*(a-b)*(b-c)*(c-a)\n",
        "    num1 = (b-c)*TrueArea1 - (c-a)*TrueArea2\n",
        "    c1 = num1/den1\n",
        "    #print (den1, c1)\n",
        "\n",
        "    den2 = (a-b)*(b-c)*(c-a)\n",
        "    num2 = (c**2 - a**2)*TrueArea2 - (b**2 - c**2)*TrueArea1\n",
        "    c2 = num2/den2\n",
        "    #print (den2, c2)\n",
        "\n",
        "    if (den1 == 0 or den2 == 0):\n",
        "      pass\n",
        "\n",
        "    compare2 = np.array([c1*x + c2 for x in np.linspace(a, b, 10)])\n",
        "    #print (compare1)\n",
        "\n",
        "    e = np.max(np.abs(compare1 - compare2))\n",
        "    #print (e)\n",
        "    if math.isnan(e):\n",
        "      #print (\"Nan detected\")\n",
        "      pass\n",
        "    if len(error) > 0:\n",
        "        if error[0] > e:\n",
        "          ans = [c, c1, c2]\n",
        "          error[0] = e\n",
        "    else:\n",
        "      if math.isnan(e) != True:\n",
        "        ans = [c, c1, c2]\n",
        "        error = [e]\n",
        "\n",
        "    #rint (e, error, math.isnan(e))\n",
        "  return ans[0], ans[1], ans[2]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvH_Svz1ISwd",
        "outputId": "f7c981cd-42c9-4735-fdcf-157b9d628122"
      },
      "source": [
        "coeffArray = []\n",
        "for i in range(256):\n",
        "  #print (i)\n",
        "  c, c1, c2 = findOptimalPoint(intervals[i], intervals[i+1], tanh)\n",
        "  coeffArray.append([c1, c2])\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyAiX_UoTCwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1243f4d7-540b-4400-899c-44a674b61dbb"
      },
      "source": [
        "coeffArray[50:55]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.074911400252175, 0.26294835338288697],\n",
              " [0.07689065543753462, 0.2677097120412446],\n",
              " [0.07891035288601293, 0.2725052456518795],\n",
              " [0.08097062090447397, 0.2773327273068449],\n",
              " [0.08307154112310883, 0.28218981016199146]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oROPv0rYYY56",
        "outputId": "16734049-8d7e-4ead-d52b-f2a894bf674f"
      },
      "source": [
        "np.searchsorted(intervals, [[1, 2], [4, 5]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32,  64],\n",
              "       [128, 160]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}