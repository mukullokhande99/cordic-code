{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_SigmoidPWLAF.ipynb","provenance":[{"file_id":"1eFI4Gc2GpzCKnzP588xnkhPUlAmqDnOE","timestamp":1616840316336},{"file_id":"1UEqiyB72arr2f1r_9PJ_kNkM2EUeVb7c","timestamp":1616003733954}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ieqrwF1uUTQ3"},"source":["Here's what I will do. \n","\n","For precision n\n","\n","I'll map an inp to activation layer lying in the range x , x + 2^(-n) to a value y. Both x and y will have precision 2^(-n). How to decide upon 'y' ? \n","\n","We will choose that y which is closest  to avg of AF(x) and AF(x + 2^-n)"]},{"cell_type":"code","metadata":{"id":"X9llfRIqVVvh"},"source":["import six\n","import numpy as np\n","import tensorflow.compat.v2 as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import keras\n","\n","!pip install git+https://github.com/google/qkeras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLbcEpzwMOrE"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","from qkeras import *\n","\n","(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","def get_one_hot(targets, nb_classes):\n","    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n","    return res.reshape(list(targets.shape)+[nb_classes])\n","#train_labels, test_labels = get_one_hot(train_labels, 10), get_one_hot(test_labels, 10)#\n","\n","train_images = train_images.reshape(train_images.shape + (1,)).astype(\"float32\")\n","test_images = test_images.reshape(test_images.shape + (1,)).astype(\"float32\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAqg84oSVY8q"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","\n","from qkeras import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsEz3KzpV8tj"},"source":["(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","def get_one_hot(targets, nb_classes):\n","    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n","    return res.reshape(list(targets.shape)+[nb_classes])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcHPyPVLXNFI"},"source":["# Tanh Intervals and Mappings"]},{"cell_type":"markdown","metadata":{"id":"GfKyAmSHXRtG"},"source":["## 8 bit"]},{"cell_type":"code","metadata":{"id":"Ek5WqZsbXA6P"},"source":["def swish(x):\n","  #global intervals, coeffArray\n","  #return x\n","  #coeff = np.array(coeffArray)\n","  #conditionArray = sum([tf.multiply(tf.cast(tf.math.logical_and(tf.math.less(x, 0.03125*(n+1)), tf.math.greater_equal(x, 0.03125*n)), tf.float32), coeff[n][0]*x + coeff[n][1]*K.ones_like(x)) for n in range(256)])\n","\n","  #return quantized_bits(17, 1)(conditionArray)\n","  #return conditionArray\n","\n","  quantizer = quantized_bits(precision+1, 1)\n","  xprime = quantizer(x)\n","  argument = 0.5*(tf.math.sigmoid(xprime) + tf.math.sigmoid(xprime + 2**(-precision)))\n","  return quantizer(argument)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tvt3G3vUWK3a"},"source":["intBits = 1\n","precision = 32\n","\n","def modelMaker(precision, intBits):\n","  model = models.Sequential()\n","  #model.add(layers.Conv2D(32, (3, 3), activation='sigmoid', input_shape=(32, 32, 3)))\n","  model.add(QConv2D(32, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          activation='sigmoid',\n","          name='c1'))\n","  model.add(QActivation('quantized_bits({}, {})'.format(precision, intBits)))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  #model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n","  model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          activation='sigmoid',\n","          name='c2'))\n","  model.add(QActivation('quantized_bits({}, {})'.format(precision, intBits)))\n","\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  #model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n","  model.add(QConv2D(64, (3,3), kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          activation='sigmoid',\n","          name='c3'))\n","  model.add(QActivation('quantized_bits({}, {})'.format(precision, intBits)))\n","\n","  model.add(layers.Flatten())\n","  #model.add(layers.Dense(64, activation='sigmoid'))\n","  model.add(QDense(64, kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          name='d1'))\n","  model.add(Activation(swish))\n","  model.add(QDense(10, kernel_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          bias_quantizer=\"quantized_bits({}, {} , alpha=1)\".format(precision, intBits),\n","          name = 'd2'))\n","  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmWyWEyQOswF"},"source":["import qkeras\n","from qkeras import *\n","from qkeras.utils import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGCqbjRy76rQ"},"source":["qmodels = []\n","histories = []\n","for i in [9, 13, 17, 33]:\n","  precision = i\n","  for epoch in range(5, 10):\n","    qmodel = modelMaker(precision, 1)\n","    qmodel.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","    history = qmodel.fit(train_images[:48000], train_labels[:48000], epochs= epoch,\n","                  validation_data=(train_images[48000:], train_labels[48000:]), verbose=False)\n","    \n","    model_save_quantized_weights(qmodel)\n","\n","    qmodels.append(qmodel)\n","    histories.append(history)\n","    qmodel.evaluate(test_images, test_labels)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SM0niIkTF7ug"},"source":["model.evaluate(test_images[5000:], test_labels[5000:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hctgwHxbzbRB"},"source":["qmodels = []\n","histories = []\n","for i in [25]:\n","  precision = i\n","  for epoch in range(3, 15):\n","    qmodel = modelMaker(precision, 1)\n","    qmodel.compile(optimizer='adam',\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","    history = qmodel.fit(train_images[:48000], train_labels[:48000], epochs= epoch,\n","                  validation_data=(train_images[48000:], train_labels[48000:]), verbose=False)\n","    \n","    model_save_quantized_weights(qmodel)\n","\n","    qmodels.append(qmodel)\n","    histories.append(history)\n","    qmodel.evaluate(test_images, test_labels)\n","  "],"execution_count":null,"outputs":[]}]}