{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantized_PWLAF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2xU3goZ11jA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d3402e-c455-4914-cc38-218c0c4bf598"
      },
      "source": [
        "import six\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "!pip install git+https://github.com/google/qkeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google/qkeras\n",
            "  Cloning https://github.com/google/qkeras to /tmp/pip-req-build-59mu224v\n",
            "  Running command git clone -q https://github.com/google/qkeras /tmp/pip-req-build-59mu224v\n",
            "Requirement already satisfied (use --upgrade to upgrade): QKeras==0.8.0 from git+https://github.com/google/qkeras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.4.1)\n",
            "Requirement already satisfied: pyparser in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (53.0.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (0.5.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (2.5)\n",
            "Requirement already satisfied: keras-tuner>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (0.24.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (4.57.0)\n",
            "Requirement already satisfied: parse==1.6.5 in /usr/local/lib/python3.6/dist-packages (from pyparser->QKeras==0.8.0) (1.6.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (0.1.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->QKeras==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.8.7)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (3.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (20.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (2.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner>=1.0.1->QKeras==0.8.0) (2.4.7)\n",
            "Building wheels for collected packages: QKeras\n",
            "  Building wheel for QKeras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for QKeras: filename=QKeras-0.8.0-cp36-none-any.whl size=148269 sha256=787caf90f3152dc1678418f5f1fe1d563b145cd4e5297a92d732f2c77a79184e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3qgpn1oj/wheels/b4/74/1d/9456d62789716894a5edd7e342b4beaef69241ac584706c68d\n",
            "Successfully built QKeras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeGejv5F2FFV"
      },
      "source": [
        "def get_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
        "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
        "\n",
        "    x_train /= 256.0\n",
        "    x_test /= 256.0\n",
        "\n",
        "    x_mean = np.mean(x_train, axis=0)\n",
        "\n",
        "    x_train -= x_mean\n",
        "    x_test -= x_mean\n",
        "\n",
        "    nb_classes = np.max(y_train)+1\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    quantizer = quantized_bits(9, 1)\n",
        "    x_train = quantizer(x_train).numpy()\n",
        "    x_test = quantizer(x_test).numpy()\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miiiHpAD2IeG"
      },
      "source": [
        "from keras import backend as K\n",
        "class MyActivation(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MyActivation, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.a = self.add_weight(name='a',\n",
        "                                      shape=(1),\n",
        "                                      initializer ='ones',  # TODO: Choose your initializer\n",
        "                                      trainable=True)\n",
        "        self.c = self.add_weight(name='c',\n",
        "                                      shape=(1),\n",
        "                                      initializer='ones',  # TODO: Choose your initializer\n",
        "                                      trainable=True)\n",
        "        super(MyActivation, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        #return tf.matmul(inputs, self.w) + self.b\n",
        "        #quantizer = quantized_bits(9, 1)\n",
        "        return K.maximum(self.a*(x + self.c), K.minimum(self.a*(x - self.c) + self.c, x))\n",
        "        #return K.maximum(K.zeros_like(x), x)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNUR3DjEWBIN"
      },
      "source": [
        "from keras import backend as K\n",
        "def swish(x, beta=10.0):\n",
        "    #Here return the c1*x + c2\n",
        "    global intervals, coeffArray\n",
        "    #idx = np.array(intervals).searchsorted(x.data())\n",
        "    idx = quantized_bits(9,1)(x)/0.03125\n",
        "    coeff = np.array(coeffArray)\n",
        "    return coeff[idx][0]*x + coeff[idx][1]*K.ones_like(x)\n",
        "    a = tf.gather(coeff, int(idx))\n",
        "    return x\n",
        "    \n",
        "    #K.stop_gradient()\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CliMUn61NM51"
      },
      "source": [
        "### Here I'll try to use the method outlined in this link\n",
        "# https://stackoverflow.com/questions/54204393/piecewise-activation-function-in-tensorflow-and-broadcasting-math-operation\n",
        "\n",
        "def swish(x):\n",
        "  global intervals, coeffArray\n",
        "  coeff = np.array(coeffArray)\n",
        "  conditionArray = sum([tf.multiply(tf.cast(tf.math.logical_and(tf.math.less(x, 0.03125*(n+1)), tf.math.greater_equal(x, 0.03125*n)), tf.float32), coeff[n][0]*x + coeff[n][1]*K.ones_like(x)) for n in range(256)])\n",
        "\n",
        "  return conditionArray\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g372k7ea2UmL"
      },
      "source": [
        "from qkeras import *\n",
        "import qkeras\n",
        "def CreateModel(shape, nb_classes, intBits):\n",
        "    x = x_in = Input(shape)\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "\n",
        "    x = QDense(256,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha = 1)\".format(intBits),\n",
        "        name=\"dense\")(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense2\")(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense3\")(x)\n",
        "\n",
        "    #x = MyActivation()(x)\n",
        "    x = Activation(swish)(x)\n",
        "\n",
        "    x = QDense(nb_classes,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense4\")(x)\n",
        "    \n",
        "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYwiSVce2O3N"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=2, restore_best_weights=True)\n",
        "\n",
        "model = CreateModel(x_train.shape[1:], y_train.shape[-1], 1)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(0.0005),\n",
        "    #optimizer='sgd',\n",
        "    metrics=[\"accuracy\"],)\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_test[:5000], y_test[:5000]), verbose=False, callbacks=[callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuNIQuD5n2-r",
        "outputId": "d0bffa3b-f366-47ee-f0c4-381bd85d63f0"
      },
      "source": [
        "from qkeras.utils import *\n",
        "model_save_quantized_weights(model)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... quantizing model\n",
            "  my_activation_3 has not been quantized\n",
            "  my_activation_4 has not been quantized\n",
            "  my_activation_5 has not been quantized\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNkFu80c2kPa",
        "outputId": "dcdc98f8-619a-473d-8d2b-2c6e1210b856"
      },
      "source": [
        "model.evaluate(x_test[5000:], y_test[5000:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 5s 29ms/step - loss: 0.0769 - accuracy: 0.9770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0768977552652359, 0.9769999980926514]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYwcmp5qTgI"
      },
      "source": [
        "# PWLAF\n",
        "\n",
        "e --> Error\n",
        "r --> Input Range\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D6a_oPdtl3W"
      },
      "source": [
        "from scipy.optimize import fsolve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6s8DQvw-Lih"
      },
      "source": [
        "#Given\n",
        "e = 0.04\n",
        "r = 8\n",
        "\n",
        "#Number of input bits\n",
        "Ninp = np.ceil(np.log(r)/np.log(2)) + np.ceil(-1*np.log(e)/np.log(2))\n",
        "\n",
        "#Number of Output/Fractional bits\n",
        "Nout = np.ceil(-1*np.log(e)/np.log(2))\n",
        "\n",
        "#Boundaries\n",
        "def f(x):\n",
        "  global e\n",
        "  return (x**3)/3 - (2*(x**5)/15 + e)\n",
        "\n",
        "xpa = fsolve(f, [1])[0]\n",
        "xpaq = r*np.ceil(xpa* (2**(Ninp))/r)/(2**Ninp)\n",
        "\n",
        "temp = 1-(e + 2**(-1*Nout))\n",
        "xs = np.arctanh(temp)\n",
        "xsq = r*np.ceil(xs* (2**(Ninp))/r)/(2**Ninp)\n",
        "\n",
        "#Permissible approximation error\n",
        "ea = e - 2**(-1*(Nout+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiqldig7amJ-"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-1*x))\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLAMQQHZuKQ6",
        "outputId": "b481834a-0ae8-478e-dac8-19c160364707"
      },
      "source": [
        "import scipy.integrate as integrate\n",
        "import scipy.special as special\n",
        "result = integrate.quad(lambda x: tanh(x), 0, 4.5)\n",
        "result[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.806976221629778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQgHXx70HkV8"
      },
      "source": [
        "We divide the given range into 256 equal segments. In each segment, we wish to make the area equal to that under the actual function.\n",
        "\n",
        "In each sub-interval we choose from a set of further 100 points, to determine thw optimal values of the constants c1 and c2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qWplFqIH9do"
      },
      "source": [
        "given_range = [0, 8]\n",
        "\n",
        "intervals = np.linspace(given_range[0], given_range[1], 257)\n",
        "from qkeras import *\n",
        "quantizer = quantized_bits(9, 3)\n",
        "intervals = sorted(list(set(quantizer(intervals).numpy())))\n",
        "intervals.append(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdlYmE4kXN1P",
        "outputId": "8ce66a4f-2cfa-4f1f-ece8-13d6798f44e4"
      },
      "source": [
        "inte"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eYbzfH3W05u",
        "outputId": "ef2d3767-874e-4b91-dc83-840e779efb14"
      },
      "source": [
        "intervals[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.03125, 0.0625, 0.09375, 0.125, 0.15625, 0.1875, 0.21875, 0.25, 0.28125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWjyr3H8KrsC"
      },
      "source": [
        "from scipy import linalg\n",
        "import math\n",
        "def findOptimalPoint(a, b, func):\n",
        "  ans = []\n",
        "  error = []\n",
        "  #print (error)\n",
        "  compare1 = np.array([sigmoid(x) for x in np.linspace(a,b, 10)])\n",
        "  for c in np.linspace(a, b, 10):\n",
        "    \n",
        "    if c == a or c==b:\n",
        "      pass\n",
        "    TrueArea1 = integrate.quad(lambda x: func(x), a, c)[0]\n",
        "    TrueArea2 = integrate.quad(lambda x: func(x), c, b)[0]\n",
        "    \n",
        "    #print (TrueArea1, TrueArea2)\n",
        "    \n",
        "      #solution = linalg.solve(np.array([[0.5*c**2 - 0.5*a**2, c-a], [0.5*b**2 - 0.5*c**2, b-c]]), np.array([TrueArea1, TrueArea2]))\n",
        "      #c1, c2 = solution[0], solution[1]\n",
        "\n",
        "    den1 = 0.5*(a-b)*(b-c)*(c-a)\n",
        "    num1 = (b-c)*TrueArea1 - (c-a)*TrueArea2\n",
        "    c1 = num1/den1\n",
        "    #print (den1, c1)\n",
        "\n",
        "    den2 = (a-b)*(b-c)*(c-a)\n",
        "    num2 = (c**2 - a**2)*TrueArea2 - (b**2 - c**2)*TrueArea1\n",
        "    c2 = num2/den2\n",
        "    #print (den2, c2)\n",
        "\n",
        "    if (den1 == 0 or den2 == 0):\n",
        "      pass\n",
        "\n",
        "    compare2 = np.array([c1*x + c2 for x in np.linspace(a, b, 10)])\n",
        "    #print (compare1)\n",
        "\n",
        "    e = np.max(np.abs(compare1 - compare2))\n",
        "    #print (e)\n",
        "    if math.isnan(e):\n",
        "      #print (\"Nan detected\")\n",
        "      pass\n",
        "    if len(error) > 0:\n",
        "        if error[0] > e:\n",
        "          ans = [c, c1, c2]\n",
        "          error[0] = e\n",
        "    else:\n",
        "      if math.isnan(e) != True:\n",
        "        ans = [c, c1, c2]\n",
        "        error = [e]\n",
        "\n",
        "    #rint (e, error, math.isnan(e))\n",
        "  return ans[0], ans[1], ans[2]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvH_Svz1ISwd",
        "outputId": "4eec57f4-97b1-4c0b-f19a-fc73fa8cc215"
      },
      "source": [
        "coeffArray = []\n",
        "for i in range(256):\n",
        "  #print (i)\n",
        "  c, c1, c2 = findOptimalPoint(intervals[i], intervals[i+1], sigmoid)\n",
        "  coeffArray.append([c1, c2])\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyAiX_UoTCwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbd6b88-c5a4-4ab4-9c26-afa6e787cddb"
      },
      "source": [
        "coeffArray[50:55]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.5763888888888888, 0.14185368092544978, 0.6050721723028996],\n",
              " [1.6076388888888888, 0.1389487749021975, 0.6097001430729274],\n",
              " [1.6388888888888888, 0.13606642402724312, 0.6143822494131755],\n",
              " [1.6701388888888888, 0.13320845830919847, 0.6191140519515355],\n",
              " [1.7013888888888888, 0.1303765961749539, 0.6238911279841882]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oROPv0rYYY56",
        "outputId": "16734049-8d7e-4ead-d52b-f2a894bf674f"
      },
      "source": [
        "np.searchsorted(intervals, [[1, 2], [4, 5]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 32,  64],\n",
              "       [128, 160]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}