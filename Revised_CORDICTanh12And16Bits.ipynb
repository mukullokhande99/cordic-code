{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Revised_CORDICTanh12And16Bits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ26nEtq70vC"
      },
      "source": [
        "# No. of Integer Bits = 1\n",
        "# No. of Magnitude Bits = 12, 16\n",
        "\n",
        "Here, we evaluate the accuracy of the Tanh activation function using the expression\n",
        "\n",
        "tanh = sinh x / cosh x\n",
        "\n",
        "Accuracies\n",
        "\n",
        "**For 12 bits:** 96.6, 97.6, 97.7, 97.8, 97.8, 97.7\n",
        "\n",
        "**For 16 bits:** 97.6, 97.7, 98.0, 97.9, 98.0, 98.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE0RNV1M7zd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f02e2eb-4a1e-4bd7-9e3c-77be341e7ff3"
      },
      "source": [
        "import multiprocessing \n",
        "\n",
        "import six\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install git+https://github.com/google/qkeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google/qkeras\n",
            "  Cloning https://github.com/google/qkeras to /tmp/pip-req-build-argn2ynw\n",
            "  Running command git clone -q https://github.com/google/qkeras /tmp/pip-req-build-argn2ynw\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.4.1)\n",
            "Collecting pyparser\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/7c/77a059dcf29b39e6c4315ce9e9c7d4959be6f13af8ee42e6d5376b599015/pyparser-1.0.tar.gz\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (50.3.2)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (2.5)\n",
            "Collecting keras-tuner>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 12.0MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.48.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/54/115f0c28a61d56674c3a5e05c46d6c3523ad196e1dcd3e2d8b119026df36/tqdm-4.54.1-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25hCollecting parse==1.6.5\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/eb/44c70a5704fdf55d26a33070a9a13a03f0d66a5f6b72cadf75620d9dc4c0/parse-1.6.5.tar.gz\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (0.1.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->QKeras==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (20.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (2.23.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner>=1.0.1->QKeras==0.8.0) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (1.24.3)\n",
            "Building wheels for collected packages: QKeras, pyparser, keras-tuner, parse, terminaltables\n",
            "  Building wheel for QKeras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for QKeras: filename=QKeras-0.8.0-cp36-none-any.whl size=143338 sha256=60a063bab87fded03f988541f4096af592a73be003e8ac6a4e90bdb344027f19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-spmqph4h/wheels/b4/74/1d/9456d62789716894a5edd7e342b4beaef69241ac584706c68d\n",
            "  Building wheel for pyparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyparser: filename=pyparser-1.0-cp36-none-any.whl size=4944 sha256=f155ff82f1d2e6667ff0edbd402bb43006b9008742450cad909e572e3c48deef\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/1c/4f/9f66cd69719aa41c2684efae758d95db7803e9fe1f65146db1\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=35a412bfb4eb97e6e8da3b9e80ce0f6f2415d023b7f06b210161e6c1fd279306\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.6.5-cp36-none-any.whl size=18178 sha256=c91da3e3524987cb553bcbdf15e5c5e0dc111904799b8279449177b80910261b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/cd/20/b1fc8e3046811c0d10f03d1027c26077c9ca396cf8d579f4e3\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=9cdf7e9bf7ef75535e8403a0c08cfe33a4eb25e039bcd5baa26e66510f545761\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built QKeras pyparser keras-tuner parse terminaltables\n",
            "Installing collected packages: parse, pyparser, tensorflow-model-optimization, terminaltables, colorama, tqdm, threadpoolctl, scikit-learn, keras-tuner, QKeras\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed QKeras-0.8.0 colorama-0.4.4 keras-tuner-1.0.2 parse-1.6.5 pyparser-1.0 scikit-learn-0.23.2 tensorflow-model-optimization-0.5.0 terminaltables-3.1.0 threadpoolctl-2.1.0 tqdm-4.54.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP79yT967qPz"
      },
      "source": [
        "def get_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
        "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
        "\n",
        "    x_train /= 256.0\n",
        "    x_test /= 256.0\n",
        "\n",
        "    x_mean = np.mean(x_train, axis=0)\n",
        "\n",
        "    x_train -= x_mean\n",
        "    x_test -= x_mean\n",
        "\n",
        "    nb_classes = np.max(y_train)+1\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T86NjHsL8qmy"
      },
      "source": [
        "from qkeras import *\n",
        "import qkeras\n",
        "def CreateQModel(shape, nb_classes, intBits):\n",
        "    x = x_in = Input(shape)\n",
        "\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "    x = QDense(256,\n",
        "        kernel_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(13, {} , alpha = 1)\".format(intBits),\n",
        "        name=\"dense\")(x)\n",
        "    x = QActivation(\"quantized_tanh(13, {})\".format(intBits), name=\"act_1\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense2\")(x)\n",
        "    x = QActivation(\"quantized_tanh(13, {})\".format(intBits), name=\"act_2\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense3\")(x)\n",
        "    x = QActivation(\"quantized_tanh(13, {})\".format(intBits), name=\"act_3\")(x)\n",
        "    x = QDense(nb_classes,\n",
        "        kernel_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(13, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense4\")(x)\n",
        "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeuD8FB58vlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19d7599-f830-4c97-c953-9cdb48b22d83"
      },
      "source": [
        "from qkeras.utils import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=2, restore_best_weights=True)\n",
        "qmodel = CreateQModel(x_train.shape[1:], y_train.shape[-1], 1)\n",
        "qmodel.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(0.0005),\n",
        "    metrics=[\"accuracy\"])\n",
        "history = qmodel.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test[:5000], y_test[:5000]), verbose=False, callbacks=[callback])\n",
        "model_save_quantized_weights(qmodel)\n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... quantizing model\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxYVsQWR8z3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc4efe2-35b3-433b-8a2c-85f0c0f607a9"
      },
      "source": [
        "qmodel.evaluate(x_test[5000:], y_test[5000:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06781864911317825, 0.9807999730110168]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5c5BVvuGvl2"
      },
      "source": [
        "tangents = 2**(-1*np.arange(1.0, 100.0, 1.0))\n",
        "lookup_arctanh = np.arctanh(tangents)\n",
        "\n",
        "def modifiedCordicTanh(arr, iterations):\n",
        "  '''\n",
        "  Returns the quantized tanh of the supplied argument x\n",
        "  '''\n",
        "  xarr = 1.2075*np.ones(shape=(len(arr), len(arr[0])))\n",
        "  yarr = np.zeros(shape = (len(arr), len(arr[0])))\n",
        "\n",
        "  global  lookup_arctanh\n",
        "  #current_vector = np.array([1.2075, 0])\n",
        "  #z = x\n",
        "\n",
        "  for i in range(1, iterations+1):\n",
        "    m = -1\n",
        "    sigma = np.sign(arr)\n",
        "    \n",
        "    xchange = m*sigma*2**(-i)*yarr\n",
        "    ychange = sigma*2**(-i)*xarr\n",
        "    arrchange = sigma*lookup_arctanh[i-1]\n",
        "\n",
        "    xarr -= xchange\n",
        "    yarr += ychange\n",
        "    arr -= arrchange\n",
        "    \n",
        "    #x = current_vector[0]\n",
        "    #y = current_vector[1]\n",
        "    #xnew = x\n",
        "    #ynew = y\n",
        "    #xnew = xnew - m*sigma*2**(-i)*y\n",
        "    #ynew = ynew + sigma*2**(-i)*x\n",
        "    #z = z - sigma*lookup_arctanh[i-1]\n",
        "    #current_vector = [xnew, ynew]\n",
        "\n",
        "  #ex = xarr + yarr\n",
        "  #eminusx = xarr - yarr\n",
        "\n",
        "  #temp1 = quantized_bits(9, 1, alpha=1)(ex - eminusx)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(ex + eminusx)\n",
        "\n",
        "  return quantized_bits(13,1, alpha=1)(yarr/xarr)\n",
        "\n",
        "  #ex = current_vector[0] + current_vector[1]\n",
        "  #eminusx = current_vector[0] - current_vector[1]\n",
        "\n",
        "  #temp1 = quantized_bits(9,1,alpha=1)(ex - eminusx)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(ex + eminusx)\n",
        "\n",
        "  #return quantized_bits(9,1, alpha=1)(temp1/temp2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnsSBXSD-F9m"
      },
      "source": [
        "x_test = x_test[5000:]\n",
        "y_test = y_test[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMXQKF7Q-Jbr"
      },
      "source": [
        "def epicGeneratePredictions(indices, iterations):\n",
        "  global justAHolder, numOfIterations\n",
        "  from keras import backend as K\n",
        "  get_third_layer_output = K.function([qmodel.layers[0].input],\n",
        "                                    [qmodel.layers[2].output])\n",
        " \n",
        "  layer3_output = get_third_layer_output([x_test])[0]\n",
        "\n",
        "  layer3_output = layer3_output[indices[0]: indices[1]]\n",
        "\n",
        "  layer3_output = modifiedCordicTanh(layer3_output, iterations)\n",
        "\n",
        "  ### Let us try and sidestep this ###\n",
        "  #for i in range(len(layer3_output)):\n",
        "  #  for j in range(len(layer3_output[0])):\n",
        "  #    layer3_output[i][j] = cordicSigmoid(layer3_output[i][j], iterations)\n",
        "\n",
        "  #justAHolder = layer3_output\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(layer3_output))), range(len(layer3_output[0])))).reshape(-1, 2)\n",
        "  #doit(arguments)\n",
        "\n",
        "  #layer3_output = justAHolder\n",
        "\n",
        "  #print (\"Done!!!\")\n",
        "\n",
        "  input_shape = qmodel.layers[4].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(256))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[4](x)\n",
        "  qm4 = Model(layer_input, x)\n",
        "\n",
        "  predictions = qm4.predict(layer3_output)\n",
        "\n",
        "  predictions = modifiedCordicTanh(predictions, iterations)\n",
        "\n",
        "  #justAHolder = predictions\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(predictions))), range(len(predictions[0])))).reshape(-1, 2)\n",
        "  #doit(arguments)\n",
        "\n",
        "  #predictions = justAHolder\n",
        "\n",
        "  #for i in range(len(predictions)):\n",
        "  #  for j in range(len(predictions[0])):\n",
        "  #    predictions[i][j] = cordicSigmoid(predictions[i][j], iterations)\n",
        "\n",
        "  input_shape = qmodel.layers[6].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(128))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[6](x)\n",
        "  qm4 = Model(layer_input, x)\n",
        "\n",
        "  predictions = qm4.predict(predictions)\n",
        "\n",
        "\n",
        "  predictions = modifiedCordicTanh(predictions, iterations)\n",
        "  #justAHolder = predictions\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(predictions))), range(len(predictions[0])))).reshape(-1, 2)\n",
        "  #doit(arguments)\n",
        "\n",
        "  #predictions = justAHolder\n",
        "\n",
        "  #for i in range(len(predictions)):\n",
        "  #  for j in range(len(predictions[0])):\n",
        "  #    predictions[i][j] = cordicSigmoid(predictions[i][j], iterations)\n",
        "\n",
        "  input_shape = qmodel.layers[8].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(128))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[8](x)\n",
        "\n",
        "  qm4 = Model(layer_input, x)\n",
        "  predictions = np.array(qm4.predict(predictions))\n",
        "\n",
        "  #answer = np.zeros_like(predictions)\n",
        "  #answer[len(predictions), predictions.argmax()] = 1\n",
        "  a = predictions\n",
        "  return (a == a.max(axis=1)[:,None]).astype(int)\n",
        "  #return answer\n",
        "\n",
        "  #return answer\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ezQHcXW-Mrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339ff0bd-ab39-49bd-8dba-d0e39772b3dc"
      },
      "source": [
        "answerVectors = []\n",
        "for iter in [2,3,4, 5, 6, 7]:\n",
        "  answerVectors.append(epicGeneratePredictions([0, 1000], iter))\n",
        "  print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmxRo0p3JTMi",
        "outputId": "a594cbb0-282e-40a8-e05a-ae5c7b9d25ae"
      },
      "source": [
        "accuracy = []\n",
        "for i in answerVectors:\n",
        "  correct = 0\n",
        "  for j in range(1000):\n",
        "    if (i[j] == y_test[j]).all():\n",
        "      correct += 1\n",
        "  accuracy.append(correct)\n",
        "\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[966, 976, 977, 978, 978, 977]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXlqnTGR3s_"
      },
      "source": [
        "# 16 Bits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2wXP20gR7A6"
      },
      "source": [
        "from qkeras import *\n",
        "import qkeras\n",
        "def CreateQModel(shape, nb_classes, intBits):\n",
        "    x = x_in = Input(shape)\n",
        "\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "    x = QDense(256,\n",
        "        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(17, {} , alpha = 1)\".format(intBits),\n",
        "        name=\"dense\")(x)\n",
        "    x = QActivation(\"quantized_tanh(17, {})\".format(intBits), name=\"act_1\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense2\")(x)\n",
        "    x = QActivation(\"quantized_tanh(17, {})\".format(intBits), name=\"act_2\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense3\")(x)\n",
        "    x = QActivation(\"quantized_tanh(17, {})\".format(intBits), name=\"act_3\")(x)\n",
        "    x = QDense(nb_classes,\n",
        "        kernel_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(17, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense4\")(x)\n",
        "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACmElQPoSVkd",
        "outputId": "c8e6094c-8f8a-4319-f01a-188a63ac1254"
      },
      "source": [
        "from qkeras.utils import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=2, restore_best_weights=True)\n",
        "qmodel = CreateQModel(x_train.shape[1:], y_train.shape[-1], 1)\n",
        "qmodel.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(0.0005),\n",
        "    metrics=[\"accuracy\"])\n",
        "history = qmodel.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test[:5000], y_test[:5000]), verbose=False, callbacks=[callback])\n",
        "model_save_quantized_weights(qmodel)\n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... quantizing model\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBDRs1kSzyE"
      },
      "source": [
        "tangents = 2**(-1*np.arange(1.0, 100.0, 1.0))\n",
        "lookup_arctanh = np.arctanh(tangents)\n",
        "\n",
        "def modifiedCordicTanh(arr, iterations):\n",
        "  '''\n",
        "  Returns the quantized tanh of the supplied argument x\n",
        "  '''\n",
        "  xarr = 1.2075*np.ones(shape=(len(arr), len(arr[0])))\n",
        "  yarr = np.zeros(shape = (len(arr), len(arr[0])))\n",
        "\n",
        "  global  lookup_arctanh\n",
        "  #current_vector = np.array([1.2075, 0])\n",
        "  #z = x\n",
        "\n",
        "  for i in range(1, iterations+1):\n",
        "    m = -1\n",
        "    sigma = np.sign(arr)\n",
        "    \n",
        "    xchange = m*sigma*2**(-i)*yarr\n",
        "    ychange = sigma*2**(-i)*xarr\n",
        "    arrchange = sigma*lookup_arctanh[i-1]\n",
        "\n",
        "    xarr -= xchange\n",
        "    yarr += ychange\n",
        "    arr -= arrchange\n",
        "    \n",
        "    #x = current_vector[0]\n",
        "    #y = current_vector[1]\n",
        "    #xnew = x\n",
        "    #ynew = y\n",
        "    #xnew = xnew - m*sigma*2**(-i)*y\n",
        "    #ynew = ynew + sigma*2**(-i)*x\n",
        "    #z = z - sigma*lookup_arctanh[i-1]\n",
        "    #current_vector = [xnew, ynew]\n",
        "\n",
        "  #ex = xarr + yarr\n",
        "  #eminusx = xarr - yarr\n",
        "\n",
        "  #temp1 = quantized_bits(9, 1, alpha=1)(ex - eminusx)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(ex + eminusx)\n",
        "\n",
        "  return quantized_bits(17,1, alpha=1)(yarr/xarr)\n",
        "\n",
        "  #ex = current_vector[0] + current_vector[1]\n",
        "  #eminusx = current_vector[0] - current_vector[1]\n",
        "\n",
        "  #temp1 = quantized_bits(9,1,alpha=1)(ex - eminusx)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(ex + eminusx)\n",
        "\n",
        "  #return quantized_bits(9,1, alpha=1)(temp1/temp2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVvTzztSWtW",
        "outputId": "77fab084-6b49-48c0-ccc2-3151b6de475c"
      },
      "source": [
        "answerVectors = []\n",
        "for iter in [2,3,4, 5, 6, 7]:\n",
        "  answerVectors.append(epicGeneratePredictions([0, 1000], iter))\n",
        "  print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9kvU51aSZaA",
        "outputId": "4b2ecc0a-79fd-485c-8826-1e33e02835b4"
      },
      "source": [
        "accuracy = []\n",
        "for i in answerVectors:\n",
        "  correct = 0\n",
        "  for j in range(1000):\n",
        "    if (i[j] == y_test[j]).all():\n",
        "      correct += 1\n",
        "  accuracy.append(correct)\n",
        "\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[976, 977, 980, 979, 980, 980]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}