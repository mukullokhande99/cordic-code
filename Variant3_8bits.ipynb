{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Revised_TanhVariant3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LjBaGTpbkcC"
      },
      "source": [
        "Here we evaluate the accuracy for Tanh activation function with the expression:\n",
        "\n",
        "Tanh = 2sigmoid(2x) - 1\n",
        "\n",
        "Accuracies:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NmuD5nJ2Ne9",
        "outputId": "3c9ddb53-b084-4c6e-c8e0-ccda73d35a6a"
      },
      "source": [
        "import multiprocessing \n",
        "\n",
        "import six\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install git+https://github.com/google/qkeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google/qkeras\n",
            "  Cloning https://github.com/google/qkeras to /tmp/pip-req-build-jy9oh0px\n",
            "  Running command git clone -q https://github.com/google/qkeras /tmp/pip-req-build-jy9oh0px\n",
            "Requirement already satisfied (use --upgrade to upgrade): QKeras==0.8.0 from git+https://github.com/google/qkeras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.19.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.4.1)\n",
            "Requirement already satisfied: pyparser in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (50.3.2)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (0.5.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (2.5)\n",
            "Requirement already satisfied: keras-tuner>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (0.23.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.6/dist-packages (from QKeras==0.8.0) (4.54.1)\n",
            "Requirement already satisfied: parse==1.6.5 in /usr/local/lib/python3.6/dist-packages (from pyparser->QKeras==0.8.0) (1.6.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (0.1.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->QKeras==0.8.0) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->QKeras==0.8.0) (4.4.2)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (3.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.8.7)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.4.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner>=1.0.1->QKeras==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23.1->QKeras==0.8.0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner>=1.0.1->QKeras==0.8.0) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner>=1.0.1->QKeras==0.8.0) (3.0.4)\n",
            "Building wheels for collected packages: QKeras\n",
            "  Building wheel for QKeras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for QKeras: filename=QKeras-0.8.0-cp36-none-any.whl size=143338 sha256=f12e6be589e87a9adf1f5c07713a49d3709188decb03bf221e6085892054a2be\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kxx44jcc/wheels/b4/74/1d/9456d62789716894a5edd7e342b4beaef69241ac584706c68d\n",
            "Successfully built QKeras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fCAtT9NbTw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc7deb6-1d94-4cca-ede8-a354e9297aaf"
      },
      "source": [
        "def get_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
        "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
        "\n",
        "    x_train /= 256.0\n",
        "    x_test /= 256.0\n",
        "\n",
        "    x_mean = np.mean(x_train, axis=0)\n",
        "\n",
        "    x_train -= x_mean\n",
        "    x_test -= x_mean\n",
        "\n",
        "    nb_classes = np.max(y_train)+1\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = get_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDwMDsL20UP"
      },
      "source": [
        "from qkeras import *\n",
        "import qkeras\n",
        "def CreateQModel(shape, nb_classes, intBits):\n",
        "    x = x_in = Input(shape)\n",
        "\n",
        "    x = Flatten(name=\"flatten\")(x)\n",
        "    x = QDense(256,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha = 1)\".format(intBits),\n",
        "        name=\"dense\")(x)\n",
        "    x = QActivation(\"quantized_tanh(9, {})\".format(intBits), name=\"act_1\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense2\")(x)\n",
        "    x = QActivation(\"quantized_tanh(9, {})\".format(intBits), name=\"act_2\")(x)\n",
        "    x = QDense(128,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense3\")(x)\n",
        "    x = QActivation(\"quantized_tanh(9, {})\".format(intBits), name=\"act_3\")(x)\n",
        "    x = QDense(nb_classes,\n",
        "        kernel_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        bias_quantizer=\"quantized_bits(9, {} , alpha=1)\".format(intBits),\n",
        "        name=\"dense4\")(x)\n",
        "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=x_in, outputs=x)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dXvoEIW2_kS",
        "outputId": "72ff4476-7f28-4a2e-e76a-870b6897f003"
      },
      "source": [
        "from qkeras.utils import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=2, restore_best_weights=True)\n",
        "qmodel = CreateQModel(x_train.shape[1:], y_train.shape[-1], 1)\n",
        "qmodel.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=Adam(0.0005),\n",
        "    metrics=[\"accuracy\"])\n",
        "history = qmodel.fit(x_train, y_train, epochs=20, batch_size=128, validation_data=(x_test[:5000], y_test[:5000]), verbose=False, callbacks=[callback])\n",
        "model_save_quantized_weights(qmodel)\n",
        "print (\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... quantizing model\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM-WtFnp4elG",
        "outputId": "ca699a4a-489d-48cb-bf2b-8c3e76e25979"
      },
      "source": [
        "qmodel.evaluate(x_test[5000:], y_test[5000:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06390399485826492, 0.9832000136375427]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q2tGtQW4vVq"
      },
      "source": [
        "tangents = 2**(-1*np.arange(1.0, 100.0, 1.0))\n",
        "lookup_arctanh = np.arctanh(tangents)\n",
        "\n",
        "def cordicTanh(x, iterations):\n",
        "  '''\n",
        "  Returns the quantized tanh of the supplied argument x\n",
        "  '''\n",
        "  \n",
        "\n",
        "  global  lookup_arctanh\n",
        "  current_vector = np.array([1.2075, 0])\n",
        "  z = 2*x\n",
        "\n",
        "  for i in range(1, iterations+1):\n",
        "    m = -1\n",
        "    sigma = np.sign(z)\n",
        "    x = current_vector[0]\n",
        "    y = current_vector[1]\n",
        "    xnew = x\n",
        "    ynew = y\n",
        "    xnew = xnew - m*sigma*2**(-i)*y\n",
        "    ynew = ynew + sigma*2**(-i)*x\n",
        "    z = z - sigma*lookup_arctanh[i-1]\n",
        "    current_vector = [xnew, ynew]\n",
        "\n",
        "  eminus2x = current_vector[0] - current_vector[1]\n",
        "  #temp1 = quantized_bits(9, 1, alpha=1)(1 + eminus2x)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(1/ temp1)\n",
        "  #temp3 = quantized_bits(9, 1, alpha = 1)(2*temp2)\n",
        "  \n",
        "  return quantized_bits(9,1, alpha=1)(temp3 - 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIcVEBBk5Yvv"
      },
      "source": [
        "from multiprocessing.dummy import Pool as ThreadPool\n",
        "justAHolder = 0\n",
        "numOfIterations = 0\n",
        "precalculated = {}\n",
        "\n",
        "\n",
        "def calcAndStore(argument):\n",
        "  global justAHolder, precalculated\n",
        "  i = argument[0]\n",
        "  j = argument[1]\n",
        "  temp1 = justAHolder[i][j]\n",
        "  '''\n",
        "  if (temp1, numOfIterations) in precalculated.keys():\n",
        "    justAHolder[i][j] = precalculated[(temp1, numOfIterations)]\n",
        "\n",
        "  else:\n",
        "    temp2 = cordicTanh(temp1, numOfIterations)\n",
        "    precalculated[(temp1, numOfIterations)] = temp2\n",
        "\n",
        "    justAHolder[i][j] = temp2\n",
        "\n",
        "  '''\n",
        "  justAHolder[i][j] = cordicTanh(temp1, numOfIterations)\n",
        "\n",
        "def doit(arguments):\n",
        "  if __name__ == '__main__':\n",
        "    pool = ThreadPool(2)\n",
        "    pool.map(calcAndStore, arguments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D06EHyTA6DVD"
      },
      "source": [
        "x_test = x_test[5000:]\n",
        "y_test = y_test[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzQCn7WapL6r"
      },
      "source": [
        "tangents = 2**(-1*np.arange(1.0, 100.0, 1.0))\n",
        "lookup_arctanh = np.arctanh(tangents)\n",
        "\n",
        "def modifiedCordicTanh(arr, iterations):\n",
        "  '''\n",
        "  Returns the quantized tanh of the supplied argument x\n",
        "  '''\n",
        "  \n",
        "\n",
        "  global  lookup_arctanh\n",
        "  current_vector = np.array([1.2075, 0])\n",
        "  arr *= 2\n",
        "\n",
        "  xarr = 1.2075*np.ones(shape=(len(arr), len(arr[0])))\n",
        "  yarr = np.zeros(shape=(len(arr), len(arr[0])))\n",
        "\n",
        "  for i in range(1, iterations+1):\n",
        "    m = -1\n",
        "    sigma = np.sign(arr)\n",
        "\n",
        "    xchange = m*sigma*2**(-i)*yarr\n",
        "    ychange = sigma*2**(-i)*xarr\n",
        "    arrchange = sigma*lookup_arctanh[i-1]\n",
        "\n",
        "    xarr -= xchange\n",
        "    yarr += ychange\n",
        "    arr -= arrchange\n",
        "    #x = current_vector[0]\n",
        "    #y = current_vector[1]\n",
        "    #xnew = x\n",
        "    #ynew = y\n",
        "    #xnew = xnew - m*sigma*2**(-i)*y\n",
        "    #ynew = ynew + sigma*2**(-i)*x\n",
        "    #z = z - sigma*lookup_arctanh[i-1]\n",
        "    #current_vector = [xnew, ynew]\n",
        "\n",
        "  return quantized_bits(9, 1, alpha=1)(2/(1 + xarr - yarr) - 1)\n",
        "\n",
        "  #eminus2x = xarr - yarr\n",
        "  #temp1 = quantized_bits(9, 1, alpha=1)(1 + eminus2x)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(1/temp1)\n",
        "  #temp3 = quantized_bits(9, 1, alpha=1)(2*temp2)\n",
        "  #return quantized_bits(9, 1, alpha=1)(temp3 - 1)\n",
        "\n",
        "  #eminus2x = current_vector[0] - current_vector[1]\n",
        "  #temp1 = quantized_bits(9, 1, alpha=1)(1 + eminus2x)\n",
        "  #temp2 = quantized_bits(9, 1, alpha=1)(1/ temp1)\n",
        "  #temp3 = quantized_bits(9, 1, alpha = 1)(2*temp2)\n",
        "  \n",
        "  #return quantized_bits(9,1, alpha=1)(temp3 - 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mbbqqjh5aWN"
      },
      "source": [
        "def epicGeneratePredictions(indices, iterations):\n",
        "  global justAHolder, numOfIterations\n",
        "  from keras import backend as K\n",
        "  get_third_layer_output = K.function([qmodel.layers[0].input],\n",
        "                                    [qmodel.layers[2].output])\n",
        " \n",
        "  layer3_output = get_third_layer_output([x_test])[0]\n",
        "\n",
        "  layer3_output = layer3_output[indices[0]: indices[1]]\n",
        "\n",
        "  layer3_output = modifiedCordicTanh(layer3_output, iterations)\n",
        "  #print (\"Done!!!!!!\")\n",
        "  #return\n",
        "\n",
        "  #print (type(layer3_output))\n",
        "  #return\n",
        "  ### Let us try and sidestep this ###\n",
        "  #for i in range(len(layer3_output)):\n",
        "  #  for j in range(len(layer3_output[0])):\n",
        "  #    layer3_output[i][j] = cordicSigmoid(layer3_output[i][j], iterations)\n",
        "\n",
        "  #justAHolder = layer3_output\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(layer3_output))), range(len(layer3_output[0])))).reshape(-1, 2)\n",
        "  #print (arguments)\n",
        "  #return\n",
        "  #doit(layer3_output)\n",
        "\n",
        "  #layer3_output = justAHolder\n",
        "\n",
        "  #print (\"Done!!!\")\n",
        "\n",
        "  input_shape = qmodel.layers[4].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(256))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[4](x)\n",
        "  qm4 = Model(layer_input, x)\n",
        "\n",
        "  predictions = qm4.predict(layer3_output)\n",
        "\n",
        "\n",
        "  predictions = modifiedCordicTanh(predictions, iterations)\n",
        "  #justAHolder = predictions\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(predictions))), range(len(predictions[0])))).reshape(-1, 2)\n",
        "  #doit(arguments)\n",
        "\n",
        "  #predictions = justAHolder\n",
        "\n",
        "  #for i in range(len(predictions)):\n",
        "  #  for j in range(len(predictions[0])):\n",
        "  #    predictions[i][j] = cordicSigmoid(predictions[i][j], iterations)\n",
        "\n",
        "  input_shape = qmodel.layers[6].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(128))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[6](x)\n",
        "  qm4 = Model(layer_input, x)\n",
        "\n",
        "  predictions = qm4.predict(predictions)\n",
        "\n",
        "  predictions = modifiedCordicTanh(predictions, iterations)\n",
        "  #justAHolder = predictions\n",
        "  #numOfIterations = iterations\n",
        "  #arguments = np.dstack(np.meshgrid(np.array(range(len(predictions))), range(len(predictions[0])))).reshape(-1, 2)\n",
        "  #doit(arguments)\n",
        "\n",
        "  #predictions = justAHolder\n",
        "\n",
        "  #for i in range(len(predictions)):\n",
        "  #  for j in range(len(predictions[0])):\n",
        "  #    predictions[i][j] = cordicSigmoid(predictions[i][j], iterations)\n",
        "\n",
        "  input_shape = qmodel.layers[8].get_input_shape_at(0)\n",
        "  layer_input = Input(shape=(128))\n",
        "  x = layer_input\n",
        "  x = qmodel.layers[8](x)\n",
        "\n",
        "  qm4 = Model(layer_input, x)\n",
        "  predictions = np.array(qm4.predict(predictions))\n",
        "\n",
        "  #answer = np.zeros_like(predictions)\n",
        "  #answer[len(predictions), predictions.argmax()] = 1\n",
        "  a = predictions\n",
        "  return (a == a.max(axis=1)[:,None]).astype(int)\n",
        "  #return answer\n",
        "\n",
        "  #return answer\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQmyyElE5mbz",
        "outputId": "ac9db847-364d-4c4c-c7ee-df26a58899e7"
      },
      "source": [
        "import time\n",
        "a = time.time()\n",
        "answerVectors = []\n",
        "for iter in [2,3,4,5,6,7, 8]:\n",
        "  answerVectors.append(epicGeneratePredictions([0, 1000], iter))\n",
        "  print (\"Done\")\n",
        "\n",
        "time.time()-a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.2047548294067383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPTaFDnBPPii",
        "outputId": "1aafe8b9-6091-4dd6-f4bc-1b278216991a"
      },
      "source": [
        "accuracy = []\n",
        "for i in answerVectors:\n",
        "  correct = 0\n",
        "  for j in range(1000):\n",
        "    if (i[j] == y_test[j]).all():\n",
        "      correct += 1\n",
        "  accuracy.append(correct)\n",
        "\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[956, 967, 971, 970, 971, 972, 972]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz1BVBnAMkWU",
        "outputId": "3c24884e-63c7-48a0-f91e-affe5976e089"
      },
      "source": [
        "len(precalculated.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0AyHbhs5xWT",
        "outputId": "325e00e0-13d6-4e36-8bd9-519c08abdd77"
      },
      "source": [
        "answerVectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzsOvaBI54Yd",
        "outputId": "fc6a5cb8-8845-4ffb-b074-f47a9fde480b"
      },
      "source": [
        "y_test[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZEFog3Jo9gR",
        "outputId": "d38137dd-960c-4217-acc5-f3cba6054fed"
      },
      "source": [
        "np.sign([[2, -3],[-9, -8]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1, -1],\n",
              "       [-1, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNeMR3PXrhFe",
        "outputId": "1473da87-424a-4728-932e-9b329c9f0106"
      },
      "source": [
        "q = quantized_bits(8,0, alpha=1)\n",
        "a = np.array([[1,2],[4,7]])\n",
        "q(a).numpy()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9921875, 0.9921875],\n",
              "       [0.9921875, 0.9921875]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhdOhRxesbyf",
        "outputId": "ad17aad8-e23b-4686-a22e-ea16bf64ce80"
      },
      "source": [
        "1/a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.5       ],\n",
              "       [0.25      , 0.14285714]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}